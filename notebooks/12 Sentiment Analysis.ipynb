{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis\n",
    "Read https://web.stanford.edu/~jurafsky/slp3/19.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlputils.lexical import Preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "stopwords = stopwords.words('portuguese')\n",
    "normalizer = Preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download LIWC resource at http://143.107.183.175:21380/portlex/images/arquivos/liwc/LIWC2007_Portugues_win.dic.txt\n",
    "# posemo = 126\n",
    "# negemo = 127\n",
    "# what more?\n",
    "positives = []\n",
    "negatives = []\n",
    "\n",
    "with open('LIWC2007_Portugues_win.dic.txt', 'r', encoding='latin') as liwc_file:\n",
    "    in_header = True\n",
    "    for line in liwc_file.readlines():\n",
    "        if not re.match('^\\d+', line):\n",
    "            parts = line.split()\n",
    "            word = parts.pop(0)\n",
    "            if '126' in parts:\n",
    "                positives.append(word)\n",
    "            elif '127' in parts:\n",
    "                negatives.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'feliz' in positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'triste' in negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_sentment_analysis(text, binary=False):\n",
    "    text = normalizer.remove_punctuation(text)\n",
    "    tokens = normalizer.tokenize_words(text)\n",
    "    tokens = normalizer.remove_stopwords(tokens)\n",
    "    \n",
    "    polarity = 0\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in positives:\n",
    "            polarity += 1\n",
    "        elif token in negatives:\n",
    "            polarity -= 1\n",
    "    if not binary:\n",
    "        return polarity\n",
    "    else:\n",
    "        if polarity < 0:\n",
    "            polarity = -1\n",
    "        elif polarity > 0:\n",
    "            polarity = 1\n",
    "        \n",
    "        return polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_sentment_analysis('Eu estou muito triste e triste')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trainset</th>\n",
       "      <th>polarity</th>\n",
       "      <th>bin_polarity</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>This show is a show that is great for adults a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This movie cannot be serious because it has a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>This is a pretty good made for TV flick of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I've seen better production quality on YouTube...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>When it first came out, this work by the Meyse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trainset polarity  bin_polarity  \\\n",
       "0     test       10             1   \n",
       "1     test        1             0   \n",
       "2     test        8             1   \n",
       "3    train        1             0   \n",
       "4    train        7             1   \n",
       "\n",
       "                                              review  \n",
       "0  This show is a show that is great for adults a...  \n",
       "1  This movie cannot be serious because it has a ...  \n",
       "2  This is a pretty good made for TV flick of the...  \n",
       "3  I've seen better production quality on YouTube...  \n",
       "4  When it first came out, this work by the Meyse...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using dataset of IMDb, available at: http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "import wget\n",
    "import os\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "\n",
    "filename = \"dataset/aclImdb_v1.tar.gz\"\n",
    "\n",
    "\n",
    "# Donwload data\n",
    "\n",
    "dataset_link = \"http://ai.stanford.edu/~amaas/data/sentiment/{}\".format(\"aclImdb_v1.tar.gz\")\n",
    "try:\n",
    "    os.mkdir(\"dataset\")\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "if not os.path.isfile(filename):\n",
    "    file = wget.download(dataset_link, out='dataset/aclImdb_v1.tar.gz')\n",
    "    tar = tarfile.open(filename, \"r:gz\")\n",
    "    tar.extractall(\"dataset\")\n",
    "    tar.close()\n",
    "\n",
    "\n",
    "# read data\n",
    "\n",
    "dataset_path = 'dataset/aclImdb'\n",
    "train_positive_files = ['train/pos/'+f for f in os.listdir(dataset_path+'/train/pos') \\\n",
    "                        if os.path.isfile(os.path.join(dataset_path+'/train/pos', f))]\n",
    "\n",
    "train_negative_files = ['train/neg/'+f for f in os.listdir(dataset_path+'/train/neg') \\\n",
    "                        if os.path.isfile(os.path.join(dataset_path+'/train/neg', f))]\n",
    "\n",
    "test_positive_files = ['test/pos/'+f for f in os.listdir(dataset_path+'/test/pos') \\\n",
    "                       if os.path.isfile(os.path.join(dataset_path+'/test/pos', f))]\n",
    "\n",
    "test_negative_files = ['test/neg/'+f for f in os.listdir(dataset_path+'/test/neg') \\\n",
    "                       if os.path.isfile(os.path.join(dataset_path+'/test/neg', f))]\n",
    "\n",
    "all_files = list(set().union(train_positive_files,train_negative_files, test_positive_files, test_negative_files))\n",
    "\n",
    "dataset = {'trainset':[], 'polarity':[], 'bin_polarity': [], 'review':[]}\n",
    "\n",
    "for file in all_files:\n",
    "    polarity = file.split('.')[0].split('_')[1]\n",
    "    with open(os.path.join(dataset_path, file), 'r') as text_file:\n",
    "        dataset['trainset'].append(file.split('/')[0])\n",
    "        bin_polarity = 1 if int(polarity) > 5 else 0  # transform into binary polarity\n",
    "        dataset['bin_polarity'].append(bin_polarity)\n",
    "        dataset['polarity'].append(polarity)\n",
    "        dataset['review'].append(text_file.readlines()[0])\n",
    "\n",
    "        \n",
    "# create dataframe\n",
    "\n",
    "dataframe = pd.DataFrame(data=dataset)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trainset</th>\n",
       "      <th>polarity</th>\n",
       "      <th>bin_polarity</th>\n",
       "      <th>review</th>\n",
       "      <th>normalized_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>This show is a show that is great for adults a...</td>\n",
       "      <td>show show great adults children sit together w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>This movie cannot be serious because it has a ...</td>\n",
       "      <td>movie serious nerdy looking kid named curtis k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>This is a pretty good made for TV flick of the...</td>\n",
       "      <td>pretty good made tv flick variety terrorists e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>I've seen better production quality on YouTube...</td>\n",
       "      <td>ive seen better production quality youtube pit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>When it first came out, this work by the Meyse...</td>\n",
       "      <td>first came work meysels brothers much criticiz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trainset polarity  bin_polarity  \\\n",
       "0     test       10             1   \n",
       "1     test        1             0   \n",
       "2     test        8             1   \n",
       "3    train        1             0   \n",
       "4    train        7             1   \n",
       "\n",
       "                                              review  \\\n",
       "0  This show is a show that is great for adults a...   \n",
       "1  This movie cannot be serious because it has a ...   \n",
       "2  This is a pretty good made for TV flick of the...   \n",
       "3  I've seen better production quality on YouTube...   \n",
       "4  When it first came out, this work by the Meyse...   \n",
       "\n",
       "                                   normalized_review  \n",
       "0  show show great adults children sit together w...  \n",
       "1  movie serious nerdy looking kid named curtis k...  \n",
       "2  pretty good made tv flick variety terrorists e...  \n",
       "3  ive seen better production quality youtube pit...  \n",
       "4  first came work meysels brothers much criticiz...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = normalizer.lowercase(text)\n",
    "    text = normalizer.remove_punctuation(text)\n",
    "    tokens = normalizer.tokenize_words(text)\n",
    "    tokens = [token for token in tokens if token not in english_stopwords]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "dataframe['normalized_review'] = dataframe['review'].apply(preprocessing)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews = dataframe[dataframe['trainset'] == 'train']['normalized_review'].values.tolist()\n",
    "train_classes = dataframe[dataframe['trainset'] == 'train']['bin_polarity'].values.tolist()\n",
    "test_reviews = dataframe[dataframe['trainset'] == 'test']['normalized_review'].values.tolist()\n",
    "test_classes = dataframe[dataframe['trainset'] == 'test']['bin_polarity'].values.tolist()\n",
    "\n",
    "transformer = TfidfVectorizer()\n",
    "transformer.fit(train_reviews)\n",
    "X = transformer.transform(train_reviews)\n",
    "X_test = transformer.transform(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erickmaziero/virtualenvs/GCC151_env/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC()\n",
    "classifier.fit(X, train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65392"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_classes, classifier.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/erickmaziero/virtualenvs/GCC151_env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_lr = LogisticRegression()\n",
    "classifier_lr.fit(X, train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88452"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_classes, classifier_lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "film really bad\n",
      "  (0, 87080)\t0.5961343855298462\n",
      "  (0, 39451)\t0.43855537677700446\n",
      "  (0, 9716)\t0.6725273049393103\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"This film was really bad!\"\n",
    "preprocessed_sentence = preprocessing(sentence)\n",
    "print(preprocessed_sentence)\n",
    "instance = transformer.transform([preprocessing(sentence)])\n",
    "print(instance)\n",
    "classifier.predict(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good film\n",
      "  (0, 45171)\t0.7750865021715609\n",
      "  (0, 39451)\t0.6318551369985488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"Good film!\"\n",
    "preprocessed_sentence = preprocessing(sentence)\n",
    "print(preprocessed_sentence)\n",
    "instance = transformer.transform([preprocessing(sentence)])\n",
    "print(instance)\n",
    "classifier.predict(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
